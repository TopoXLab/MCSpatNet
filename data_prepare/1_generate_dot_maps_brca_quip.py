import numpy as np
import glob
import os
import sys
import skimage.io as io
from scipy import ndimage
import scipy.io as sio
import cv2
import scipy


# Configuration variables
in_dir = '../../datasets/brcadata3'
out_root_dir = '../../datasets/brcadata3_cc'
# Define cell classes
classes_max_indx=3
# lymph: blue,  tumor: red, epithelium: green, other: pink
color_set = {1:(0,162,232),2:(255,0,0),3:(0,255,0),4:(255,255,0)}
# Define rescaling rate of images
img_scale = 0.5
remove_duplicates = False # if True will remove duplicate of cells annotated within 5 pixel distance

"""
    This code assumes the input has the following format (which is generated by extraction from quip using the code in https://github.com/david-belinsky-sbu/Dataset_Tools ):
        - for each WSI, there is folder under in_dir with the slide name
        - Within each slide folder there is: 
            Images folder: the image patches labelled from that slide 
            Labels folder: the mat files with the labels for each patch in images
        - The mat file has the following variables: 
            inst_centroid: array of shape n x 2, n is number of cells, and coordinates are (x,y)
            inst_type: array holding the cell class type for each cell in inst_centroid. The class types are sequential integers starting from 1. 
                        This is why the color_set dictionary has keys starting from 1 that represent the cell class types.
       
"""

def gaussian_filter_density(img,points, point_class_map, out_filepath, start_y=0, start_x=0, end_y=-1, end_x=-1):
    '''
        Build a KD-tree from the points, and for each point get the nearest neighbor point.
        The default Guassian width is 9.
        Sigma is adaptively selected to be min(nearest neighbor distance*0.125, 2) and truncate at 2*sigma.
        After generation of each point Gaussian, it is normalized and added to the final density map.
        A visualization of the generated maps is saved in <slide_name>_<img_name>.png and <slide_name>_<img_name>_solid.png
    '''
    img_shape=[img.shape[0],img.shape[1]]
    print("Shape of current image: ",img_shape,". Totally need generate ",len(points),"gaussian kernels.")
    density = np.zeros(img_shape, dtype=np.float32)
    density_class = np.zeros((img.shape[0], img.shape[1], point_class_map.shape[2]), dtype=np.float32)
    if(end_y <= 0):
        end_y = img.shape[0]
    if(end_x <= 0):
        end_x = img.shape[1]
    gt_count = len(points)
    if gt_count == 0:
        return density
    leafsize = 2048
    # build kdtree
    tree = scipy.spatial.KDTree(points.copy(), leafsize=leafsize)
    # query kdtree
    distances, locations = tree.query(points, k=2)
    print ('generate density...')
    
    max_sigma = 2; # kernel size = 4, kernel_width=9

    for i, pt in enumerate(points):
        pt2d = np.zeros(img_shape, dtype=np.float32)
        if(pt[1] < start_y or pt[0] < start_x or pt[1] >= end_y or pt[0] >= end_x):
            continue
        pt[1] -= start_y
        pt[0] -= start_x
        if int(pt[1])<img_shape[0] and int(pt[0])<img_shape[1]:
            pt2d[int(pt[1]),int(pt[0])] = 1.
        else:
            continue
        if gt_count > 1:
            sigma = (distances[i][1])*0.125
            sigma = min(max_sigma, sigma)
        else:
            sigma = max_sigma;

        kernel_size = min(max_sigma*2, int(2*sigma + 0.5))
        sigma = kernel_size / 2
        kernel_width = kernel_size * 2 + 1
        # if(kernel_width < 9):
        #     print('i',i)
        #     print('distances',distances.shape)
        #     print('kernel_width',kernel_width)
        pnt_density = scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant',truncate=2)
        pnt_density /= pnt_density.sum()
        density += pnt_density
        class_indx = point_class_map[int(pt[1]),int(pt[0])].argmax()
        density_class[:,:,class_indx] = density_class[:,:,class_indx] + pnt_density


    density_class.astype(np.float16).dump(out_filepath)
    density.astype(np.float16).dump(os.path.splitext(out_filepath)[0] + '_all.npy')
    io.imsave(out_filepath.replace('.npy', '.png'), (density/density.max()*255).astype(np.uint8))
    io.imsave(out_filepath.replace('.npy', '_solid.png'), ((density>0)*255).astype(np.uint8))
    for s in range(1,density_class.shape[-1]):
        io.imsave(out_filepath.replace('.npy', '_s'+str(s) + '_solid.png'), ((density_class[:,:,s]>0)*255).astype(np.uint8))
    print ('done.')
    return density.astype(np.float16), density_class.astype(np.float16)


if __name__== "__main__":
    '''
        For each WSI, loop over the patches and their labels. 
            Re-scale the patch image the labelled cell centers. 
            Create a visualization of the cell classes with different colors overlaid on the patch image. Saved as <slide name>_<img_name>_img_with_dots.jpg
            Save classification dot annotation map as <slide name>_<img_name>_gt_dots.npy and 
            Save detection dot annotation map as <slide name>_<img_name>_gt_dots_all.npy 
            Generate Gaussian maps, where a Gaussian is created at each cell center. The width of the Gaussian is such that cell do not intersect.
                Saved as <slide name>_<img_name>.npy
                The Gaussian maps are later used as dilated dot maps by converting to a binary mask where all pixels > 0 are set to 1 and the rest to zero.                
            
    '''
    out_img_dir = os.path.join(out_root_dir, 'images')
    out_gt_dir = os.path.join(out_root_dir, 'gt_custom')
    if not os.path.exists(out_root_dir):
        os.mkdir(out_root_dir)
    if not os.path.exists(out_img_dir):
        os.mkdir(out_img_dir)
    if not os.path.exists(out_gt_dir):
        os.mkdir(out_gt_dir)

    svs_list = glob.glob(os.path.join(in_dir, '*'))

    for svs_path in svs_list:
        if(not os.path.isdir(svs_path)):
            continue;
        print('svs_path',svs_path)
        svs_filename = os.path.split(svs_path)[-1]
        svs_name = svs_filename.split('.')[0]
        patches_img_list = glob.glob(os.path.join(svs_path, 'Images', '*.png'))

        for patch_img_path in patches_img_list:
            print('patch_img_path',patch_img_path)

            # read img
            im_filename =  os.path.split(patch_img_path)[-1]
            out_gt_dmap_filepath = os.path.join(out_gt_dir,svs_name + '_' + im_filename[:-len('.png')]  + '.npy')
            img = io.imread(patch_img_path)[:,:,0:3]

            # read mat file
            mat_filepath = os.path.join(svs_path, 'Labels', im_filename[:-len('.png')]+'.mat')
            mat = sio.loadmat(mat_filepath)

            # read and scale centroids
            centroids = (mat["inst_centroid"] * img_scale).astype(int)
            class_types = mat["inst_type"].squeeze()

            # scale img
            img2 = cv2.resize(img, (int(img.shape[1]*img_scale+0.5), int(img.shape[0]*img_scale+0.5)))
            io.imsave(os.path.join(out_img_dir,svs_name + '_' + im_filename),img2)

            # init label arr
            patch_label_arr_dots = np.zeros((img2.shape[0],img2.shape[1],classes_max_indx+1),dtype=np.uint8)
            patch_label_arr_dots_custom = np.zeros((img2.shape[0],img2.shape[1],classes_max_indx+1))
            # print('centroids',centroids.shape)
            # print('class_types',class_types.shape)
            centroids[(np.where(centroids[:,1] >= img2.shape[0]), 1)]=img2.shape[0]-1
            centroids[(np.where(centroids[:,0] >= img2.shape[1]), 0)]=img2.shape[1]-1

            # Generated of ground truth classification dot annotation map
            for dot_class in range(1,classes_max_indx+1):
                patch_label_arr = np.zeros((img2.shape[0],img2.shape[1]))
                patch_label_arr[(centroids[np.where(class_types == dot_class)][:,1],centroids[np.where(class_types == dot_class)][:,0])] = 1
                patch_label_arr_dots[:,:, dot_class] = patch_label_arr
                patch_label_arr = ndimage.convolve(patch_label_arr, np.ones((5,5)), mode='constant', cval=0.0)
                img2[np.where(patch_label_arr > 0)] = color_set[dot_class]

            # Remove duplicate dots
            if (remove_duplicates):
                for c in range(patch_label_arr_dots.shape[-1]):
                    tmp = ndimage.convolve(patch_label_arr_dots[:, :, c], np.ones((5, 5)), mode='constant', cval=0.0)
                    duplicate_points = np.where(tmp > 1)
                    while (len(duplicate_points[0]) > 0):
                        y = duplicate_points[0][0]
                        x = duplicate_points[1][0]
                        patch_label_arr_dots[max(0, y - 2):min(patch_label_arr_dots.shape[0] - 1, y + 3),
                        max(0, x - 2):min(patch_label_arr_dots.shape[1] - 1, x + 3), c] = 0
                        patch_label_arr_dots[y, x, c] = 1
                        tmp = ndimage.convolve(patch_label_arr_dots[:, :, c], np.ones((5, 5)), mode='constant',
                                               cval=0.0)
                        duplicate_points = np.where(tmp > 1)

            # Generate the detection ground truth dot map
            patch_label_arr_dots_all = patch_label_arr_dots[:, :, :].sum(axis=-1)
            # Save Dot maps
            patch_label_arr_dots.astype(np.uint8).dump(
                os.path.join(out_gt_dir, svs_name + '_' +im_filename[:-len('.png')] + '_gt_dots.npy'))
            patch_label_arr_dots_all.astype(np.uint8).dump(
                os.path.join(out_gt_dir, svs_name + '_' +im_filename[:-len('.png')] + '_gt_dots_all.npy'))

            # Visualize of all cell types overlaid dots on img
            for dot_class in range(1, patch_label_arr_dots.shape[-1]):
                print('dot_class', dot_class)
                print('patch_label_arr_dots[:,:,dot_class]', patch_label_arr_dots[:, :, dot_class].sum())
                patch_label_arr = patch_label_arr_dots[:, :, dot_class].astype(int)
                patch_label_arr = ndimage.convolve(patch_label_arr, np.ones((5, 5)), mode='constant', cval=0.0)
                img2[np.where(patch_label_arr > 0)] = color_set[dot_class]
            io.imsave(os.path.join(out_gt_dir, svs_name + '_' +im_filename[:-len('.png')] + '_img_with_dots.jpg'), img2)

            # Generate the Gaussian maps.
            # It is important to not do this for each class separately because this may result in intersections in the detection map
            mat_s_points = np.where(patch_label_arr_dots > 0)
            points = np.zeros((len(mat_s_points[0]), 2))
            print(points.shape)
            points[:, 0] = mat_s_points[1]
            points[:, 1] = mat_s_points[0]
            patch_label_arr_dots_custom_all, patch_label_arr_dots_custom = gaussian_filter_density(img2, points,
                                                                                                   patch_label_arr_dots,
                                                                                                   out_gt_dmap_filepath)

            # patch_label_arr_dots_custom = np.zeros((patch_label_arr_dots.shape))
            # patch_label_arr_dots_custom_all = np.zeros((patch_label_arr_dots.shape[0], patch_label_arr_dots.shape[1]))
            # # Generate the Gaussian maps
            # for dot_class in range(1,classes_max_indx+1):
            #     mat_s_points = np.where(patch_label_arr_dots[:,:, dot_class] > 0)
            #     points = np.zeros((len(mat_s_points[0]),2))
            #     print(points.shape)
            #     points[:, 0]=mat_s_points[1]
            #     points[:, 1]=mat_s_points[0]
            #     patch_label_arr_dots_custom[:,:,dot_class] = gaussian_filter_density(img2,points, out_gt_dmap_filepath.replace('.npy','_s'+str(dot_class)+'.npy'))
            # patch_label_arr_dots_custom.astype(np.float16).dump(out_gt_dmap_filepath)
            #
            #
